{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 神经网络入门\n",
    "python复习，神经网络基本概念，正负面情感分析，miniflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本操作复习  \n",
    "numpy是用来操作矩阵及其中的元素的  \n",
    "[numpy](https://docs.scipy.org/doc/numpy/reference/)  \n",
    "注意multiply与dot的区别:元素相乘与点乘  \n",
    "转置：` m.T `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络  \n",
    "神经网络是一种使用试图使用线性系统和多维空间来模拟处理现实问题的做法  \n",
    "### 单个神经元  \n",
    "单个神经元是一个线性方程：$y = f(x) =\\sum\\limits_{n=1}^N w_{i} \\times x_{i}$  \n",
    "x为输入,y为输出,有N个输入  \n",
    "关于激活函数的部分有一个专题,写好附在这里(待补充)\n",
    "### 网络\n",
    "多个神经元的结合（部分神经元的输出作为其他神经元德输入）完善了一个多项式拟合系统.而如果项数足够多,由泰勒展开,它可以描述所有的数学现象  \n",
    "然而当我们遇到更加复杂的问题,这种做法似乎会出现混沌？  \n",
    "（待补充）\n",
    "### 回归迭代\n",
    "定义好神经元之后,我们通过 $y_{真实} - y_{计算}$ 来得到误差.再由误差对w的导数来调整误差(抽象说法,思想来源为欧拉方法),这种做法称为梯度下降  \n",
    "通过向前传播计算各个节点的输出(也就是下一个节点的输入)直到最后一个, 然后反向传播利用 已经用计算出的输出 来计算在该点的梯度, 进而确定下一次迭代的 $w$ 的取值.\n",
    "疑问:梯度下降的时候,对于权重 $w$ 的下一次迭代的取值,是不是有更多改进的地方?\n",
    "(待补充)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核心代码\n",
    "\n",
    "def train(self, features, targets):\n",
    "### 训练部分:这是一个只有两层的神经网络\n",
    "特征是二维矩阵: 每一行是一个样本,每一列是一个特征  \n",
    "输出是一维矩阵: 其实就一个数  \n",
    "初始化变量  \n",
    "```\n",
    "            n_records = features.shape[0]\n",
    "            delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "            delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "            for X, y in zip(features, targets):\n",
    "```\n",
    "定义隐藏层的输入输出\n",
    "```\n",
    "            hidden_inputs = np.dot(self.weights_input_to_hidden.T,X[:,None])\n",
    "            hidden_outputs = self.activation_function(hidden_inputs)\n",
    "```         \n",
    "定义输出层的输入输出\n",
    "```\n",
    "            final_inputs = np.dot(self.weights_hidden_to_output.T,hidden_outputs)\n",
    "            final_outputs = final_inputs\n",
    "```            \n",
    "### 向后传播\n",
    "定义误差函数,y是$y_{实际}$,final_outputs是计算出的y\n",
    "```\n",
    "            error = (y - final_outputs)\n",
    "```            \n",
    "在隐藏层的权重要使用隐藏层的偏差来计算,所以要先由 $y_{实际}$ 算出隐藏层的实际输出偏差  \n",
    "针对每一个节点,反向传播公式为: $\\delta \\, w_i \\propto \\frac{\\partial E}{\\partial w_i }  $  \n",
    "$ \\frac{\\partial E}{\\partial w_i} =  -(\\, y - \\widehat{y}\\,) \\, f'(x) \\, x_i $ , 一个$x$对应一个$w$  \n",
    "E是这个节点的error\n",
    "\n",
    "```\n",
    "hidden_error = np.dot(self.weights_hidden_to_output,error)\n",
    "```  \n",
    "即:$(\\, \\widehat{y} - y \\,)$ ,也就是$-(\\, y - \\widehat{y}\\,) $\n",
    "\n",
    "计算输出偏差对权重 $w$ 的导数 \n",
    "```\n",
    "            output_error_term = error\n",
    "            hidden_error_term = hidden_error*hidden_outputs*(1 - hidden_outputs) \n",
    "```\n",
    "即:$ -(\\, y - \\widehat{y}\\,) \\, f'(x)$\n",
    "```\n",
    "            delta_weights_i_h += np.dot(X[:,None], hidden_error_term.T)\n",
    "            delta_weights_h_o += np.dot(hidden_outputs, output_error_term)\n",
    "```\n",
    "最后得到$-(\\, y - \\widehat{y}\\,) \\, f'(x) \\, x_i $\n",
    "\n",
    "更新权重 $w$ 的值,$\\delta \\, w_i \\propto \\frac{\\partial E}{\\partial w_i }  $  的比例为learning_rate.\n",
    "```\n",
    "        self.weights_hidden_to_output += delta_weights_h_o*self.lr/ n_records  \n",
    "        self.weights_input_to_hidden += delta_weights_i_h*self.lr/ n_records  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我会对计算过程中遇到的点乘与元素相乘的区别加以讨论,然后定义一套自己的数据存放规则(待补充)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有关反向传播回归权重的知识点推导(待补充)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
